{
  "periods": [
    1
  ],
  "iterations": [
    [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ]
  ],
  "rewards": [
    [
      -90037.7890625,
      -85290.0625,
      -83185.3203125,
      -82652.796875,
      -79656.5625,
      -79846.875,
      -78654.578125,
      -78337.09375,
      -77398.609375,
      -77679.859375,
      -77736.109375,
      -77454.859375,
      -77773.609375,
      -77904.859375,
      -77698.609375,
      -78111.109375,
      -77829.859375,
      -77848.609375,
      -77904.859375,
      -78017.359375
    ]
  ],
  "rewards_mean": [
    -79550.96953125
  ],
  "rewards_std": [
    3211.169936295978
  ],
  "rewards_min": [
    -90037.7890625
  ],
  "rewards_max": [
    -77398.609375
  ],
  "policy_gradients_norm": [
    [
      2.8731112193032833e-06,
      0.0016028665991244086,
      0.9999999621178778,
      0.9999999200969011,
      1.000000063054734,
      1.0000000411993133,
      1.0000000343528657,
      0.9999999250131144,
      0.9999999574457592,
      0.00019162380018530417,
      0.005619984834379593,
      1.2269128048189516e-07,
      0.0002632999070045174,
      1.5718692198252272e-07,
      0.0003933077114466034,
      0.42780267502945085,
      0.9999993948888799,
      1.0000000276451495,
      0.9999996796541849,
      0.9999999969043933
    ]
  ],
  "losses": [],
  "learning_rates": [
    []
  ],
  "convergence": []
}